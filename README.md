# âš¡ FlinkLite â€” A Real-Time Distributed Stream Processing Engine

**FlinkLite** is a lightweight real-time stream processing engine built in **Scala** using **Akka Streams** and **Apache Kafka**, inspired by Apache Flink. It supports **event-time processing**, **out-of-order event handling**, **windowing**, **checkpointing**, and **real-time observability** using **Prometheus** and **Grafana**.

---

## ğŸš€ Features

* âœ… Event-time processing with **sliding windows**
* ğŸ”„ Handles **out-of-order events** using watermarks and allowed lateness
* ğŸ“‚ Disk-based **checkpointing** every 5 seconds
* ğŸ“ˆ Real-time **monitoring** with Prometheus + Grafana
* ğŸ”¥ Supports multiple event types: `important`, `critical`, `normal`
* ğŸ“¤ Optionally forwards processed results to another Kafka topic
* ğŸ§ª Simulates production-like disorder and throughput for testing

---

## ğŸ“¦ Tech Stack

| Component     | Tool / Framework      |
| ------------- | --------------------- |
| Language      | Scala                 |
| Streaming     | Akka Streams          |
| Messaging     | Apache Kafka          |
| Metrics       | Prometheus            |
| Visualization | Grafana               |
| Checkpointing | JSON-based disk files |
| Build Tool    | sbt                   |

---

## ğŸ— Architecture

```
Kafka Producer â†’ [Kafka Topic: flink-events]
                      â†“
           [Akka Streams: FlinkLite Core]
           - Watermark Manager
           - Sliding Window Manager
           - Disk Checkpointing
                      â†“
     [Prometheus Exporter]   [Kafka Output Topic (optional)]
                      â†“
                  [Grafana]
```

---

## âš™ï¸ How to Run

### 1. Start Kafka + Create Topics

```bash
# Start Zookeeper
bin/zookeeper-server-start.sh config/zookeeper.properties

# Start Kafka
bin/kafka-server-start.sh config/server.properties

# Create topics
kafka-topics.sh --create --topic flink-events --bootstrap-server localhost:9092
kafka-topics.sh --create --topic processed-events --bootstrap-server localhost:9092
```

---

### 2. Run the Stream Engine

```bash
sbt run
```

This:

* Consumes from `flink-events`
* Processes only `"important"` and `"critical"` messages
* Maintains window buffers and checkpoints to disk
* Exposes Prometheus metrics at `http://localhost:1234/metrics`

---

### 3. Simulate Event Stream with Disorder

```bash
for i in {1..100}; do
  id=$i
  now=$(date +%s%3N)
  offset=$((10000 * (RANDOM % 6)))
  timestamp=$((now - offset))

  case $((RANDOM % 3)) in
    0) msg="important" ;;
    1) msg="normal" ;;
    2) msg="critical" ;;
  esac

  echo "{\"id\": $id, \"timestamp\": $timestamp, \"message\": \"$msg\"}" | \
    kafka-console-producer --broker-list localhost:9092 --topic flink-events > /dev/null
done
```

---

### 4. Set Up Prometheus

Edit `prometheus.yml`:

```yaml
scrape_configs:
  - job_name: 'flinklite'
    static_configs:
      - targets: ['localhost:1234']
```

Then run:

```bash
./prometheus --config.file=prometheus.yml
```

---

### 5. Visualize with Grafana

* Open `http://localhost:3000`
* Add Prometheus as data source
* Example queries:

  * `rate(flinklite_events_total[1m])` â†’ event throughput
  * `flinklite_windows_flushed_total` â†’ number of flushed windows
  * `flinklite_watermark_timestamp` â†’ stream time progress
  * `flinklite_last_checkpoint_time` â†’ last checkpoint time in ms

---

## ğŸ“Š Metrics Tracked

| Metric                            | Description                        |
| --------------------------------- | ---------------------------------- |
| `flinklite_events_total`          | Total number of processed events   |
| `flinklite_windows_flushed_total` | Number of windows flushed          |
| `flinklite_watermark_timestamp`   | Current watermark timestamp        |
| `flinklite_last_checkpoint_time`  | Time (ms) of last checkpoint write |

---

## ğŸ§  Internals

### âœ… Watermarking Logic

* Keeps track of max observed timestamp
* Watermark = max timestamp âˆ’ allowed lateness (5s)
* Events older than watermark + 5s are **discarded**

### âœ… Windowing Logic

* Sliding window: size = 10s, slide = 5s
* Events are placed in all overlapping windows
* Flushed when watermark surpasses window end

### âœ… Checkpointing

* Saved every 5 seconds to `checkpoint.json`
* Restored on restart to prevent data loss

---

## ğŸ“‚ Project Structure

```
FlinkLite/
â”œâ”€â”€ src/main/scala/
â”‚   â”œâ”€â”€ Main.scala
â”‚   â”œâ”€â”€ model/Event.scala
â”‚   â”œâ”€â”€ time/
â”‚   â”‚   â”œâ”€â”€ WindowManager.scala
â”‚   â”‚   â””â”€â”€ SessionWindowManager.scala
â”‚   â”œâ”€â”€ watermark/WatermarkManager.scala
â”‚   â”œâ”€â”€ checkpoint/CheckpointManager.scala
â”‚   â””â”€â”€ metrics/Metrics.scala
â”œâ”€â”€ prometheus.yml
â”œâ”€â”€ build.sbt
â””â”€â”€ .gitignore
```

---

## ğŸš° Future Enhancements

* Add support for **session windows**
* Introduce **joins** across event streams
* Persist outputs to **Cassandra** or **PostgreSQL**
* Add support for **custom aggregation operators**
* Include **Docker Compose** for easier setup

---

## ğŸ“¬ Feedback

Feel free to raise issues or contribute with PRs. Star â­ the repo if you liked the project!
